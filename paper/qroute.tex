% ****** Start of file apssamp.tex ******
%
%   This file is part of the APS files in the REVTeX 4.2 distribution.
%   Version 4.2a of REVTeX, December 2014
%
%   Copyright (c) 2014 The American Physical Society.
%
%   See the REVTeX 4 README file for restrictions and more information.
%
% TeX'ing this file requires that you have AMS-LaTeX 2.0 installed
% as well as the rest of the prerequisites for REVTeX 4.2
%
% See the REVTeX 4 README file
% It also requires running BibTeX. The commands are as follows:
%
%  1)  latex apssamp.tex
%  2)  bibtex apssamp
%  3)  latex apssamp.tex
%  4)  latex apssamp.tex
%
\documentclass[%
 reprint,
%superscriptaddress,
%groupedaddress,
%unsortedaddress,
%runinaddress,
%frontmatterverbose, 
%preprint,
%preprintnumbers,
%nofootinbib,
%nobibnotes,
%bibnotes,
 amsmath,amssymb,
 aps,
%pra,
%prb,
%rmp,
%prstab,
%prstper,
%floatfix,
]{revtex4-2}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
%\usepackage{hyperref}% add hypertext capabilities
%\usepackage[mathlines]{lineno}% Enable numbering of text and display math
%\linenumbers\relax % Commence numbering lines

%\usepackage[showframe,%Uncomment any one of the following lines to test
%%scale=0.7, marginratio={1:1, 2:3}, ignoreall,% default settings
%%text={7in,10in},centering,
%%margin=1.5in,
%%total={6.5in,8.75in}, top=1.2in, left=0.9in, includefoot,
%%height=10in,a5paper,hmargin={3cm,0.8in},
%]{geometry}
\bibliographystyle{apsrev4-1}

\begin{document}

\preprint{APS/123-QED}

\title{Qubit routing using Graph neural network aided Monte Carlo tree search}

\author{Animesh Sinha}
\email{animesh.sinha@research.iiit.ac.in}
\author{Utkarsh Azad}
\email{utkarsh.azad@research.iiit.ac.in}
\author{Jai Bardhan}
\author{Kalp Shah}
\author{Bhuvanesh Sridharan}
\author{Dr. Harjinder Singh}
\email{laltu@iiit.ac.in}
\affiliation{%
    Center for Computational Natural Science, International Institute of Information Technology, Hyderabad.
}%

\date{\today}% It is always \today, today,
%  but any date may be explicitly specified

\begin{abstract}
    Current day quantum computers support two qubit operations only on physically neighboring qubits. To respect this constraint when compiling quantum circuits to target hardware, we need to insert swap gates. It's desirable that the depth of the final circuit with the inserted gates is minimized, this article aims to provide an efficient solution to this problem.

    We use Monte Carlo tree search to perform qubit routing, which is aided by a Graph neural network used to evaluate the value function and action probabilities for each state. Minimizing circuit depth involves being able to perform operations in parallel, we using mutex locks to efficiently maintain this information and present it to the neural network. This should be of relevance to both the particular task of Qubit routing and as a general idea in several combinatorial optimizations.
\end{abstract}

\keywords{Qubit Routing, Quantum Compilation, Quantum Circuit Transformation, Reinforcement Learning, Monte Carlo Tree Search, Graph Neural Network}
\maketitle

%\tableofcontents

\section{\label{sec:intro}Introduction}

\subsection{\label{sec:intro-defn}Describing the Problem}

Present day quantum computer come in a variety of hardware architectures, but a pervading problem across them is limited qubit connectivity for two qubit operations and high error rates, which compound when increasing the depth of the circuit, due to which the execution of deep quantum circuits is an unfeasible task.

To make an arbitrary quantum circuit executable on a given target architecture, a quantum compiler has to insert SWAP gates so that gates in the original circuit only ever occur between qubits located at adjacent nodes, a process known as Qubit Routing. The process produce a new circuit, possibly with a greater depth, that implements the same unitary function as the original circuit while respecting
the topological constraints \citep{qroute_dqn2}.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.38\linewidth}
        \includegraphics[width=\linewidth]{images/device-grid.jpg}
        \caption{3$\times$3 Grid Architecture}
    \end{subfigure}
    \begin{subfigure}[b]{0.56\linewidth}
        \includegraphics[width=\linewidth]{images/device-ibmqx.jpg}
        \caption{IBM QX-20 Architecture as a graph of nodes}
    \end{subfigure}
    \caption{Examples of common architectures}
    \label{fig:topology-example}
\end{figure}

Minimizing the depth of the quantum circuit resulting from the routing process is the objective we are trying to achieve.


\subsection{\label{sec:intro-related}Related Work}

The problem of Qubit routing was outlined and presented with a graph based architecture-agnostic solution by \citet{qroute_tket}. The routing problem was phrased as a reinforcement learning problem in a combinatorial action space by \citet{qroute_dqn1}. They also proposed the use of simulated annealing to search through the combinatorial action space, aided by a Feed Forward Neural Network to judge the long-term expected compilation time. This was extended to use Double Deep Q-learning and Prioritized Experience Replay by \citet{qroute_dqn2}.

Monte Carlo Tree Search (MCTS) has been a popular reinforcement learning algorithm \citep{mcts_bandits_0, mcts_bandits_1, mcts_uct} leading to great success in a variety of domains, playing puzzle games like Chess and Go \citep{mcts_alphago} for instance.
A version of MCTS, adapted for better exploration on Asymmetric Trees was proposed by \citet{mcts_assymetric}, which will be the formulation of choice for us.
An unaided Monte Carlo Tree Search in the context of minimizing the total volume of quantum circuits (number of gates, ignoring the parallelization) was proposed by \citet{qroute_mcts}, and has produced promising results.

\subsection{\label{sec:intro-contribution}Contribution of this work}

This article proposes using Monte Carlo tree search for the task of total Depth minimization, as an easier to train and better performing machine learning setting.
\begin{itemize}
    \item We use an array of mutex locks to represent the information the Agent needs to know to be able to make effective use of parallelization.
    \item We propose a graph neural network architecture to approximate the value function and the policy function for any given state of the system.
    \item We provide a simple python package to test and visualize routing algorithms with different neural net architectures, combining algorithms, reward structures, etc.
\end{itemize}
From these changes, we hope to gain an agent which is not immediately greedy since it can only see the current state and not effectively plan for the future, and to stabilize the decision process which suffered from the randomness of introduced by simulated annealing.

\begin{figure*}[t]
    \includegraphics[width=\linewidth]{images/mcts-steps.jpg}
    \caption{\label{fig:mcts-explainer}
        Scaling of Initial Depth overhead with size of hardware}
\end{figure*}

\section{\label{sec:method}Method}

The solution to this problem involves maintaining a convenient representation of the current state of the total system, that is the remainder of the problem and the current state of the solution, and evolving it using actions chosen by our model. In this section we describe both these steps. (Code for the complete simulation and visualization is available on \url{https://github.com/AnimeshSinha1309/quantum-rl})

\subsection{\label{sec:method-state}State representation}

\subsubsection{\label{sec:method-state-circuit}Circuit Representation}

Each circuit is input as a set of qubit $\mathbb{Q}$ and an partially ordered set of operations $\mathbb{O} = \{(q_x, q_y) \vert q_x, q_y \in \mathbb{Q}\}$.
We convert this to a lists of lists representation as in \citet{qroute_dqn2}, where for each logical qubit, $q_i$, we store the list of all other qubits that participate in 2 qubit operations with $q_i$, in the order they appear in the logical circuit.

\label{para:method-state-circuit-gatecond}So a gate $(q_x, q_y)$ is executable if and only if the first $i - 1$ operations for $q_x$ and $j - 1$ operations for $q_y$ have been executed and the $i^{th}$ operation for $q_x$ is $q_y$ and the $j^{th}$ operation for $q_y$ is $q_x$.

\subsubsection{\label{sec:method-state-mutex}Mutex Locks}

The core of the routing problem lies in the parallelization of the actions under the constraints that two operations in the same timestep cannot operate on the same qubit. A way to think about this is to call the qubits "resources" and the operations that are trying to use the "consumers" of this resource. This is reminiscent of several parallel processes competing for the same memory. We try to adapt the same solution of mutual exclusions locks \citep{mutex_dijkstra} in this version of the problem.

Our output circuit will consist of 2 types of operations, CNOTs and SWAPs. All single qubit operations are much faster than any 2 qubit operations and therefore ignored. Depending on the primitive gates available on the hardware, a SWAP can either be an elementary gate and equivalent to CNOT, or be decomposed into 3 CNOT gates. So the locks array, which is a part of the state, should be a vector $l_t \in Z_+^{\#n}$. For each of the nodes, it states the number of timesteps it will stay locked for. This vector is also presented to the Neural Network so help it learn to avoid attempting to use the same node and several operations.

\subsubsection{\label{sec:method-state-full}The State Object}

Our simulation will proceed in timesteps. The entire specification of our system will be done by the state $s_t = (C, D, q_t, p_t, l_t)$.
\begin{itemize}
    \item $q_t \in \mathbb{Z}^{n\_nodes}_{n\_nodes}$ is a vector denoting the qubit locations, the i\textsuperscript{th} element in the array denotes the index of the logical qubit which is present on the i\textsuperscript{th} element.
    \item $p_t \in \mathbb{Z}^{n\_nodes}_{+}$ is a vector which represents the progress of each qubit on the circuit.
    \item $l_t \in \mathbb{Z}^{n\_nodes}_{+}$ is a vector which stores the number of operations this qubit will stay locked for. It's a mutex lock of sorts, ensuring that a CNOT operation blocks a qubit for the next timestep, or a swap gate blocks it for the next 3.
    \item $C$ - the circuit object. Common across all states, contains the list of lists representation of the circuit.
    \item $D$ - the device object. Allows access to the shortest distance between any two nodes on the device graph, thereby also checking if a two qubit gate is admissible on the hardware given the nodes it has to operate on.
\end{itemize}

\subsubsection{\label{sec:method-state-actions}Action Space}

Through our search, we evolve the state using Actions. These actions are one of two types: $SWAP(a, b)$ or $CNOT(a, b)$. A $SWAP$ action evolves the mapping by swapping elements in the qubit locations array $q_t$. A $CNOT$ action is only performed when a gate in the logical circuit is executable, as described here (\ref{para:method-state-circuit-gatecond}), and satisfies the topological constraints of the circuit.

\subsection{\label{sec:method-rl}Reinforcement Learning Setting}

Given a state $s$, the value function of that state is the expected total reward in the future.
\begin{equation}
    V(s) = \max_{s^\prime} Q(s, a)
\end{equation}

The Q-function is the total expected reward in the future after we took an action A from state S. This is updated in each step of our simulation for all the states that were visited.
\begin{equation}
    Q(s, a) = \sum_{s^\prime} R(s, a, s^\prime) + \gamma V(s^\prime)
\end{equation}

We want to find the $a$, for each $s$ which maximizes $Q(s, a)$, however, since we have to approximate $Q(s, a)$ by explicitly trying out all A, we employ a tree search to maximize this function.

\subsection{\label{sec:method-mcts}Monte Carlo Tree Search}

To search over the action space, we employ a tree search which consists of 4 steps. The first is a selection step which chooses the optimal node to explore. This choice is made by maximizing the Upper Confidence Bound on Trees value, which is a sum of the expected reward $Q$ and expected standard deviation multiplied by a constant $c$. This constant weights the exploration tendency of the agent against the exploitation (choosing the best action based on current knowledge). The next step, called Expansion, explores the futures of the selected state. The third step is rollout, where we use our Neural Network to approximate the value function of the state. The fourth and final step is using the explicitly obtained rewards and the value function at the expanded state to update the $Q$ functions of all states in it's ancestory.

\begin{equation}
    UCT_s(a) = Q(s, a) + \frac{\sqrt{n(s, a)}}{1 + n(a)} \times p(s, a)
\end{equation}

We recognize that running MCTS on this problem results in a highly assymetric tree, since some actions block a lot of other actions, and some actions don't interfere with any other action at all. So we add a Dirichlet noise term in the prior generated by our neural network to prevent our tree search from getting stuck down a single path. The formulation of MCTS for asymmetric trees is adapted from \citet{mcts_assymetric}

\subsection{\label{sec:method-architecture}Neural Network Architecture}

Our tree search needs a value function approximator and a policy function approximator. The Value function will help us evaluate the total expected rewards from a state. The policy function will help choose which actions are with exploring. It's seems easier to learn a good policy function, since it's heavily dependent only on the current state, as opposed to a value function which depends a lot on the expected rewards in the future.

is a neural network which helps approximate the value function, which is an estimate of the number of additional timesteps that the circuit might take to compile, and the policy function, which is a vector of size $n\_edges$, with real valued elements between 0 and 1.

\begin{figure*}[btp]
    \includegraphics[width=\textwidth]{images/network-architecture.jpg}
    \caption{\label{fig:network-architecture}
        Graph Neural Network Architecture with a Value head and a Policy head}
\end{figure*}


\section{\label{sec:results}Results}

\subsection{\label{sec:results-random}Random Test Circuits}

We test the scaling of our algorithms on randomized circuits of varying number of gates to schedule and the number of qubits on target hardware.

We note that our method is relatively unphased by the growth in the size of the hardware, and scales better than other methods as the number of operations to schedule grow.

\begin{figure}[H]
    \includegraphics[width=\linewidth]{images/results-random.png}
    \caption{\label{fig:results-random}
        Comparative performance against other methods across real world hardware}
\end{figure}


\subsection{\label{sec:results-small}Small Realistic Circuits}

A full layer in a quantum circuit refers to a logical circuit that has operations on all qubits such that each qubit is involved in exactly one operation. Such a circuit is perfectly parallelizable and can be executed in a single step. Therefore is serves as a test for the initial mapping as well as a sanity check for the parallelization step.

Given a good initial mapping, we manage to transform the circuit with no depth overhead. The results for our default algorithm (Not made specifically for this task, are shown in the graph \ref{fig:results-small})

\begin{figure}[H]
    \includegraphics[width=\linewidth]{images/results-small.png}
    \caption{\label{fig:results-small}
        Scaling of Initial Depth overhead with size of hardware}
\end{figure}


\subsection{\label{sec:results-realistic}Large Realistic Circuit}

\begin{figure*}[t]
    \includegraphics[width=\linewidth]{images/results-large.png}
    \caption{\label{fig:results-small}
        Scaling of Initial Depth overhead with size of hardware}
\end{figure*}

\begin{table*}[t]
    \caption{\label{tab:large-circuits}%
        Results of our algorithm on a set of realistic test circuits
    }
    \begin{ruledtabular}
        \begin{tabular}{ll|rrrrr}
            \multicolumn{2}{c}{\textrm{Input Circuit}} & \multicolumn{5}{c}{\textrm{Output Circuit Depth}} \\

            \textrm{Name} & \textrm{Number of Gates} & \textrm{Qroute} & \textrm{PyTket Depth} & \textrm{Qiskit-Basic} & \textrm{Qiskit-Stochastic} & \textrm{Qiskit-Sabre} \\

            \colrule
            rd84\_142 	    &  154 &  154 &  145 &  227 &  156 &  196 \\
            adr4\_197 	    & 1343 & 1738 & 1743 & 2057 & 1879 & 1940 \\
            radd\_250 	    & 1405 & 1845 & 1707 & 2210 & 2013 & 2146 \\
            z4\_268 	    & 1498 & 1942 & 2036 & 2300 & 2145 & 2238 \\
            sym6\_145 	    & 1701 & 2180 & 2204 & 2537 & 2475 & 2509 \\
            misex1\_241 	& 2100 & 2712 & 2854 & 3365 & 3051 & 3163 \\
            rd73\_252 	    & 2319 & 2922 & 3199 & 3602 & 3320 & 3461 \\
            cycle10\_2\_110 & 2648 & 3372 & 3706 & 4150 & 3862 & 3983 \\
            square\_root\_7 & 3089 & 3776 & 3997 & 5409 & 4372 & 4404 \\
            sqn\_258 	    & 4459 & 5712 & 5788 & 6622 & 6269 & 6499 \\
            rd84\_253 	    & 5960 & 7450 & 8063 & 9178 & 8345 & 8746 \\
        \end{tabular}
    \end{ruledtabular}
\end{table*}

\subsection{\label{sec:results-rnd}Speed of Transformation Process}

Our Method is significantly faster than all other classical methods while still producing decent results. All our large circuit benchmarks are with 100 MCTS runs per step. The Following Image shows the time taken by our algorithm and Cirq. We do not have this for over 2000 gates since Cirq didn't manage to output a result in over 2 days.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{images/dummy_plot.png}
    \caption{Time Taken as a function of Circuit Size}
    \label{fig:results-time}
\end{figure}

\section{Discussion and Future Scope}

This method of Quantum Circuit Transformation provides competitive and many a times superior performance to other methods. However, this is my no means a definitive solution to the task of Quantum Circuit Transformations, and offers great scope of improvement. We believe that the following are avenues in which the algorithm can be significantly improved:
\begin{itemize}
    \item Augmenting the Neural Network to take the future gates as an input. We propose to use a Transformer architecture for this, to learn a mapping from arbitrary-length list of gates to a feature vector which can be used in the Graph Neural Network to estimate the value function better.
    \item Finding more systematic approaches to manage the hyperparameters, e.g. Exploration-Exploitation tradeoff constant, Reward Parameters, etc.
\end{itemize}
Our software library allows easy access to implementing these neural networks by changing just a single file. We hope that this will aid future improvements and research in the task of quantum circuit transformations.

\appendix

\subsection{\label{sec:method-mcts}2-Stage Monte Carlo Tree Search}

This is the basic structure of a generic Monte Carlo Tree Search algorithm aided by a value network and a policy network \citep{mcts_alphago}.

\begin{algorithm}[H]
    \caption{Monte Carlo Tree Search}
    \label{algmcts}
    \begin{algorithmic}
        \STATE {\bfseries Input:} state $s_t$
        \STATE Initialize root $\leftarrow$ \textbf{new node}($s_t$, solution)
        \LOOP
            \STATE node $\gets$ root
            \REPEAT
            \STATE Compute \textbf{UCT} values using prior from model + noise
            \STATE action $\gets$ action from node with maximum UCT value
            \IF{state.child[action] $\neq$ null}
                \STATE node $\gets$ node.child[action]
            \ELSE
                \IF{action is commit}
                    \STATE next-state $\gets$ \textbf{step} (node.state, node.solution)
                    \STATE \sbox0{$\vcenter{\hbox{$\begin{array}{|c|c|c|c|c|} \hline 0 & 0 & 0 & \ldots & 0 \\ \hline\end{array}$}}$}
                    next-solution $\leftarrow \underbrace{\vrule width0pt depth \dimexpr\dp0 + .3ex\relax\copy0}_{\textrm{\text{|device.edges|}}}$
                \ELSE
                    \STATE next-state $\gets$ node.state
                    \STATE next-solution $\gets$ node.solution with a set bit at action index
                \ENDIF
                \STATE state.child[action] $\gets$ \textbf{new node} (node.state, next-solution)
                \STATE \textbf{store} reward[node, action] $\gets$ \textbf{reward}(node.state, node.solution) - \textbf{reward}(next-state, next-solution)
            \ENDIF
            \UNTIL{previous action was \textrm{expand}}
            \STATE final-state $\gets$ \textbf{step} (node.state, node.solution)
            \STATE estimated-reward $\gets$ \textbf{evaluation} from model of final-state
            \WHILE{state $\neq$ root}
                \STATE parent-action $\gets$ action which led to node from it's parent node
                \STATE node $\gets$ node.parent
                \STATE estimated-reward $\gets$ reward[node, parent-action] + estimated-reward $\times$ discount-factor
                \STATE \textbf{update} node.q-value[action] $\gets$ (estimated-reward $\times$ 1 + node.q-value[action] $\times$ node.n-value[action]) / (node.n-value[action] + 1)
                \STATE \textbf{update} node.n-value[action] $\gets$ node.n-value[action] + 1
            \ENDWHILE
        \ENDLOOP
        \STATE \textbf{memorize} the q-values and n-values at the root node for training the model later

    \end{algorithmic}
\end{algorithm}

\nocite{*}

\bibliography{qroute}% Produces the bibliography via BibTeX.

\end{document}
%
% ****** End of file apssamp.tex ******
